import re
import time
import tempfile
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from urllib.parse import urlparse, parse_qs, unquote
from openai import OpenAI
import shutil
import os

# OpenAI í´ë¼ì´ì–¸íŠ¸ (í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”)
client = OpenAI()

def resolve_redirect_url(url: str, timeout=10) -> str:
    """
    ë‹¨ì¶• URL(naver.me ë“±)ì„ ì‹¤ì œ URLë¡œ ë³€í™˜
    (link.naver.com/bridge ì²˜ë¦¬ í¬í•¨)
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # ì„¸ì…˜ ì‚¬ìš©ìœ¼ë¡œ ì¿ í‚¤ ìœ ì§€
        session = requests.Session()
        session.headers.update(headers)
        
        # HEAD ìš”ì²­ìœ¼ë¡œ ìµœì¢… URL í™•ì¸
        resp = session.head(url, timeout=timeout, allow_redirects=True)
        final_url = resp.url

        # HEAD ì‹¤íŒ¨í•˜ë©´ GETìœ¼ë¡œ ì¬ì‹œë„
        if resp.status_code >= 400 or final_url == url:
            resp = session.get(url, timeout=timeout, allow_redirects=True, stream=True)
            final_url = resp.url
            resp.close()  # ìŠ¤íŠ¸ë¦¼ ë‹«ê¸°

        # ğŸ”¹ Naver bridge URL ì²˜ë¦¬
        if "link.naver.com/bridge" in final_url:
            qs = parse_qs(urlparse(final_url).query)
            if "url" in qs:
                decoded = unquote(qs["url"][0])
                print("ğŸ”¹ Bridge URL â†’ ì‹¤ì œ URL:", decoded)
                return decoded

        return final_url
    except requests.exceptions.Timeout:
        print("âš ï¸ ë¦¬ë‹¤ì´ë ‰íŠ¸ URL í•´ì„ ì‹œê°„ì´ˆê³¼")
        return url
    except requests.exceptions.RequestException as e:
        print(f"âš ï¸ ë¦¬ë‹¤ì´ë ‰íŠ¸ URL í•´ì„ ì‹¤íŒ¨: {e}")
        return url
    except Exception as e:
        print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return url

def try_requests_first(url: str, timeout=10) -> dict | None:
    """
    requests + BeautifulSoupìœ¼ë¡œ ê°„ë‹¨í•œ ê¸°ì‚¬ êµ¬ì¡° ë¹ ë¥´ê²Œ ì¶”ì¶œ
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        }
        
        session = requests.Session()
        session.headers.update(headers)
        
        resp = session.get(url, timeout=timeout)
        resp.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒì‹œ ì˜ˆì™¸ ë°œìƒ
        
        content_type = resp.headers.get("Content-Type", "")
        if "text/html" not in content_type:
            print(f"âš ï¸ HTMLì´ ì•„ë‹Œ ì½˜í…ì¸  íƒ€ì…: {content_type}")
            return None

        soup = BeautifulSoup(resp.text, "html.parser")
        
        # ë©”íƒ€ íƒœê·¸ì—ì„œ ì œëª© ìš°ì„  ì¶”ì¶œ ì‹œë„
        title = ""
        meta_title = soup.find("meta", property="og:title")
        if meta_title and meta_title.get("content"):
            title = meta_title["content"].strip()
        elif soup.title:
            title = soup.title.text.strip()
        
        # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
        for tag in soup(["script", "style", "nav", "header", "footer", "aside"]):
            tag.decompose()
        
        body = soup.get_text(separator="\n", strip=True)
        
        # ë¹ˆ ì¤„ ì •ë¦¬
        body = re.sub(r'\n\s*\n', '\n', body)
        
        return {"title": title, "body": body[:4000]}
        
    except requests.exceptions.Timeout:
        print("âš ï¸ requests ìš”ì²­ ì‹œê°„ì´ˆê³¼")
        return None
    except requests.exceptions.RequestException as e:
        print(f"âš ï¸ requestsë¡œ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return None

def fetch_with_selenium(url: str, wait_time=10) -> dict:
    """
    Seleniumìœ¼ë¡œ ê¸°ì‚¬ ë³¸ë¬¸ ë° ì œëª© ì¶”ì¶œ (ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬í•¨)
    """
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--blink-settings=imagesEnabled=false")
    options.add_argument("--disable-extensions")
    options.add_argument("--disable-default-apps")
    options.add_argument("--disable-popup-blocking")
    options.add_argument("--disable-notifications")
    options.add_argument("--mute-audio")
    options.add_argument("--disable-logging")
    options.add_argument("--disable-web-security")
    options.add_argument("--window-size=1920,1080")

    temp_dir = None
    driver = None

    try:
        temp_dir = tempfile.mkdtemp()
        options.add_argument(f"--user-data-dir={temp_dir}")

        driver = webdriver.Chrome(options=options)
        
        # í˜ì´ì§€ ë¡œë”© íƒ€ì„ì•„ì›ƒ ì„¤ì •
        driver.set_page_load_timeout(wait_time)
        
        # ë¦¬ì†ŒìŠ¤ ì°¨ë‹¨ìœ¼ë¡œ ì†ë„ í–¥ìƒ
        driver.execute_cdp_cmd('Network.enable', {})
        driver.execute_cdp_cmd('Network.setBlockedURLs', {
            "urls": ["*.png", "*.jpg", "*.jpeg", "*.gif", "*.css", "*.woff", "*.ttf", "*.svg", "*.ico"]
        })

        title = ""
        body_text = ""

        driver.get(url)

        # DOM ë¡œë”© ëŒ€ê¸°
        WebDriverWait(driver, wait_time).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )

        title = driver.title.strip()

        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ íŠ¹ë³„ ì²˜ë¦¬
        if "blog.naver.com" in url:
            try:
                # iframe ëŒ€ê¸° ë° ì „í™˜
                iframe_locator = (By.ID, "mainFrame")
                WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located(iframe_locator)
                )
                iframe = driver.find_element(*iframe_locator)
                driver.switch_to.frame(iframe)
                
                # ì½˜í…ì¸  ë¡œë”© ëŒ€ê¸°
                time.sleep(1)

                # ë‹¤ì–‘í•œ ì…€ë ‰í„° ì‹œë„
                selectors = [
                    (By.CLASS_NAME, "se-main-container"),
                    (By.ID, "postViewArea"),
                    (By.CLASS_NAME, "post-view"),
                    (By.CLASS_NAME, "post_ct")
                ]
                
                article = None
                for selector in selectors:
                    try:
                        article = driver.find_element(*selector)
                        break
                    except:
                        continue
                
                if article:
                    body_text = article.text.strip()
                else:
                    # ì „ì²´ bodyì—ì„œ ì¶”ì¶œ
                    body_text = driver.find_element(By.TAG_NAME, "body").text.strip()
                    
            except Exception as e:
                print(f"âš ï¸ ë„¤ì´ë²„ ë¸”ë¡œê·¸ iframe ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                # ê¸°ë³¸ body ì¶”ì¶œë¡œ fallback
                try:
                    body_text = driver.find_element(By.TAG_NAME, "body").text.strip()
                except:
                    pass
        else:
            # ì¼ë°˜ ì‚¬ì´íŠ¸ ì²˜ë¦¬
            try:
                # article íƒœê·¸ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                article = driver.find_element(By.TAG_NAME, "article")
                body_text = article.text.strip()
            except:
                # article íƒœê·¸ê°€ ì—†ìœ¼ë©´ body ì „ì²´ ì‚¬ìš©
                body = driver.find_element(By.TAG_NAME, "body")
                body_text = body.text.strip()

    except Exception as e:
        print(f"âŒ Selenium ë³¸ë¬¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
    finally:
        if driver:
            driver.quit()
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir, ignore_errors=True)

    return {"title": title, "body": body_text[:4000]}

def fetch_article_content(url: str) -> dict:
    """
    requestsë¡œ ë¨¼ì € ì‹œë„ í›„ ì‹¤íŒ¨ ì‹œ selenium fallback
    (ë„¤ì´ë²„ ë¸”ë¡œê·¸ëŠ” ëª¨ë°”ì¼ URLë¡œ ìë™ ë³€í™˜)
    """
    print(f"ğŸ” ê¸°ì‚¬ ë‚´ìš© ì¶”ì¶œ ì‹œì‘: {url}")
    
    # ğŸ”¹ ë„¤ì´ë²„ ë¸”ë¡œê·¸ URLì„ ëª¨ë°”ì¼ URLë¡œ ë³€í™˜
    original_url = url
    if "blog.naver.com" in url and not url.startswith("https://m."):
        url = url.replace("https://blog.naver.com", "https://m.blog.naver.com")
        print(f"ğŸ”„ ëª¨ë°”ì¼ URLë¡œ ë³€í™˜: {url}")

    # requests ë¨¼ì € ì‹œë„
    print("ğŸš€ requestsë¡œ ì‹œë„ ì¤‘...")
    article = try_requests_first(url)
    
    if article and article["body"] and len(article["body"].strip()) > 100:
        print("âœ… requestsë¡œ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œ")
        return article
    
    # requests ì‹¤íŒ¨ì‹œ selenium ì‚¬ìš©
    print("ğŸ”„ Seleniumìœ¼ë¡œ ì¬ì‹œë„...")
    result = fetch_with_selenium(original_url)  # ì›ë³¸ URL ì‚¬ìš©
    
    if result and result["body"]:
        print("âœ… Seleniumìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œ")
    else:
        print("âŒ ëª¨ë“  ë°©ë²• ì‹¤íŒ¨")
    
    return result

def summarize_text(article: dict) -> str:
    """
    GPTë¡œ ê¸°ì‚¬ ë‚´ìš©ì„ í•µì‹¬ ìœ„ì£¼ë¡œ ìš”ì•½ (ì œëª© í¬í•¨)
    """
    title = article.get("title", "")
    body = article.get("body", "")

    if not body or len(body.strip()) < 50:
        return "âœ… ìš”ì•½\n- ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì—†ìŒ\n- ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ\n- ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì ‘ê·¼ í•„ìš”\n- \n- \n- "

    # ë³¸ë¬¸ì´ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
    if len(body) > 3000:
        body = body[:3000] + "..."

    prompt = f"""
ë‹¤ìŒ ì œëª©ê³¼ ë³¸ë¬¸ì„ ë³´ê³  ê¸°ì‚¬ ë‚´ìš©ì„ í•µì‹¬ë§Œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
- ëˆ„ê°€, ë¬´ì—‡ì„, ì–¸ì œ, ì–´ë””ì„œ, ì™œ, ì–´ë–»ê²Œ í–ˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ
- ê° í•­ëª©ì€ 30ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
- ìŒìŠ´ì²´ ì‚¬ìš© (ì˜ˆ: "~í•¨", "~ì„")
- ì •í™•í•œ ì‚¬ì‹¤ë§Œ í¬í•¨

ì¶œë ¥ í˜•ì‹:
âœ… ìš”ì•½
- (ì²« ë²ˆì§¸ í•µì‹¬ ë‚´ìš©)
- (ë‘ ë²ˆì§¸ í•µì‹¬ ë‚´ìš©)
- (ì„¸ ë²ˆì§¸ í•µì‹¬ ë‚´ìš©)
- (ë„¤ ë²ˆì§¸ í•µì‹¬ ë‚´ìš©)
- (ë‹¤ì„¯ ë²ˆì§¸ í•µì‹¬ ë‚´ìš©)
- (ì—¬ì„¯ ë²ˆì§¸ í•µì‹¬ ë‚´ìš©)

ì œëª©: "{title}"

ë³¸ë¬¸: "{body}"
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_completion_tokens=400,
            temperature=0.3  # ì¼ê´€ì„± ìˆëŠ” ìš”ì•½ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ ì„¤ì •
        )

        summary = response.choices[0].message.content.strip()
        
        # í˜•ì‹ ê²€ì¦
        if not summary.startswith("âœ… ìš”ì•½"):
            summary = "âœ… ìš”ì•½\n" + summary
            
        return summary
        
    except Exception as e:
        print(f"âŒ GPT ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return f"âœ… ìš”ì•½\n- ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ\n- ì œëª©: {title[:30]}\n- ë‚´ìš© ê¸¸ì´: {len(body)}ì\n- ìˆ˜ë™ í™•ì¸ í•„ìš”\n- \n- "

def url_summary(chat) -> str | None:
    """
    í…ìŠ¤íŠ¸ì—ì„œ URLì„ ì¶”ì¶œí•˜ê³  ê¸°ì‚¬ ìš”ì•½ ìˆ˜í–‰
    chat: ChatContext ê°ì²´ ë˜ëŠ” ë¬¸ìì—´
    """
    # chat ê°ì²´ ì²˜ë¦¬
    if hasattr(chat, 'message') and hasattr(chat.message, 'msg'):
        msg = chat.message.msg
    elif isinstance(chat, str):
        msg = chat
    else:
        print("âŒ ì˜ëª»ëœ chat ê°ì²´ í˜•ì‹")
        return None
    
    # URL íŒ¨í„´ ê°œì„  (ë” ì •í™•í•œ ë§¤ì¹­)
    url_pattern = re.compile(
        r'https?://(?:[-\w.])+(?:[:\d]+)?(?:/(?:[\w/_.])*(?:\?(?:[\w&=%.])*)?(?:#(?:[\w.])*)?)?',
        re.IGNORECASE
    )
    url_match = url_pattern.search(msg)

    if not url_match:
        print("âŒ ë©”ì‹œì§€ì— URLì´ ì—†ìŠµë‹ˆë‹¤:", msg)
        return None

    url = url_match.group(0).rstrip('.,;!?)')  # ë¬¸ì¥ë¶€í˜¸ ì œê±°
    print("âœ… ë©”ì‹œì§€ì—ì„œ URL ë°œê²¬:", url)

    try:
        # ğŸ”¹ ë‹¨ì¶• URL(ë¦¬ë‹¤ì´ë ‰íŠ¸) í’€ê¸° + ë¸Œë¦¬ì§€ URL ì²˜ë¦¬
        resolved_url = resolve_redirect_url(url)
        print("ğŸ”¹ ìµœì¢… URL:", resolved_url)

        # ê¸°ì‚¬ ë‚´ìš© ì¶”ì¶œ
        article = fetch_article_content(resolved_url)
        
        if not article or not article.get("body"):
            print("âŒ ê¸°ì‚¬ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return "âœ… ìš”ì•½\n- ê¸°ì‚¬ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨\n- ì‚¬ì´íŠ¸ ì ‘ê·¼ ë¶ˆê°€ëŠ¥\n- ìˆ˜ë™ìœ¼ë¡œ í™•ì¸ í•„ìš”\n- \n- \n- "

        # GPTë¡œ ìš”ì•½ ìƒì„±
        summary = summarize_text(article)

        print(f"\nğŸ”¹ ì œëª©: {article.get('title', 'N/A')}")
        print(f"ğŸ”¹ ë³¸ë¬¸ ê¸¸ì´: {len(article.get('body', ''))}ì")
        print("ğŸ”¹ ìš”ì•½ ê²°ê³¼:")
        print(summary)
        
        return summary

    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return f"âœ… ìš”ì•½\n- ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)[:30]}\n- ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ê°€ëŠ¥ì„±\n- ì ì‹œ í›„ ì¬ì‹œë„ ê¶Œì¥\n- \n- \n- "

# í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜
def test_url_summary(test_url: str):
    """
    í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜
    """
    print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ URL: {test_url}")
    result = url_summary(test_url)
    print("=" * 50)
    print(result)
    return result