import re
import time
import tempfile
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from openai import OpenAI

# OpenAI í´ë¼ì´ì–¸íŠ¸ (í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”)
client = OpenAI()


def try_requests_first(url: str, timeout=3) -> dict | None:
    """
    requests + BeautifulSoupìœ¼ë¡œ ê°„ë‹¨í•œ ê¸°ì‚¬ êµ¬ì¡° ë¹ ë¥´ê²Œ ì¶”ì¶œ
    """
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers, timeout=timeout)
        if not resp.ok or "text/html" not in resp.headers.get("Content-Type", ""):
            return None

        soup = BeautifulSoup(resp.text, "html.parser")
        title = soup.title.text.strip() if soup.title else ""
        body = soup.get_text(separator="\n")
        return {"title": title, "body": body[:4000]}
    except Exception as e:
        print("âš ï¸ requestsë¡œ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨:", e)
        return None


def fetch_with_selenium(url: str, wait_time=3) -> dict:
    """
    Seleniumìœ¼ë¡œ ê¸°ì‚¬ ë³¸ë¬¸ ë° ì œëª© ì¶”ì¶œ (ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬í•¨)
    """
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--blink-settings=imagesEnabled=false")
    options.add_argument("--disable-extensions")
    options.add_argument("--disable-default-apps")
    options.add_argument("--disable-popup-blocking")
    options.add_argument("--disable-notifications")
    options.add_argument("--mute-audio")

    temp_dir = tempfile.mkdtemp()
    options.add_argument(f"--user-data-dir={temp_dir}")

    driver = webdriver.Chrome(options=options)

    # ë¦¬ì†ŒìŠ¤ ì°¨ë‹¨
    driver.execute_cdp_cmd('Network.enable', {})
    driver.execute_cdp_cmd('Network.setBlockedURLs', {
        "urls": ["*.png", "*.jpg", "*.jpeg", "*.gif", "*.css", "*.woff", "*.ttf", "*.svg"]
    })

    title = ""
    body_text = ""

    try:
        driver.get(url)

        WebDriverWait(driver, wait_time).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )

        title = driver.title.strip()

        if "blog.naver.com" in url:
            try:
                WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located((By.ID, "mainFrame"))
                )
                iframe = driver.find_element(By.ID, "mainFrame")
                driver.switch_to.frame(iframe)
                time.sleep(0.5)

                try:
                    article = driver.find_element(By.CLASS_NAME, "se-main-container")
                except:
                    article = driver.find_element(By.ID, "postViewArea")
                body_text = article.text.strip()
            except Exception as e:
                print("âš ï¸ ë„¤ì´ë²„ ë¸”ë¡œê·¸ iframe ì¶”ì¶œ ì‹¤íŒ¨:", e)
        else:
            body = driver.find_element(By.TAG_NAME, "body")
            body_text = body.text.strip()

    except Exception as e:
        print("âŒ Selenium ë³¸ë¬¸ ì¶”ì¶œ ì˜¤ë¥˜:", e)
    finally:
        driver.quit()

    return {"title": title, "body": body_text[:4000]}


def fetch_article_content(url: str) -> dict:
    """
    requestsë¡œ ë¨¼ì € ì‹œë„ í›„ ì‹¤íŒ¨ ì‹œ selenium fallback
    (ë„¤ì´ë²„ ë¸”ë¡œê·¸ëŠ” ëª¨ë°”ì¼ URLë¡œ ìë™ ë³€í™˜)
    """
    # ğŸ”¹ ë„¤ì´ë²„ ë¸”ë¡œê·¸ URLì„ ëª¨ë°”ì¼ URLë¡œ ë³€í™˜
    if "blog.naver.com" in url and not url.startswith("https://m."):
        url = url.replace("https://blog.naver.com", "https://m.blog.naver.com")

    article = try_requests_first(url)
    if article and article["body"].strip():
        return article
    return fetch_with_selenium(url)


def summarize_text(article: dict) -> str:
    """
    GPTë¡œ ê¸°ì‚¬ ë‚´ìš©ì„ í•µì‹¬ ìœ„ì£¼ë¡œ ìš”ì•½ (ì œëª© í¬í•¨)
    """
    title = article.get("title", "")
    body = article.get("body", "")

    if not body:
        return "- ë³¸ë¬¸ ì—†ìŒ\n- \n- \n- "

    prompt = f"""
ì œëª©ê³¼ ë³¸ë¬¸ì„ ë³´ê³ 
ê¸°ì‚¬ ë‚´ìš©ì„ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜.
ëˆ„ê°€ ë­˜ ì–´ë–»ê²Œ í–ˆëŠ”ì§€, ì¥ì†Œì™€ ì£¼ì²´, ëŒ€ìƒ êµ¬ì²´ì ìœ¼ë¡œ ë§í•´ì¤˜ì•¼
ë‚´ìš©ì˜ í˜¼ë™ì´ ì—†ìŒ.
ê¸°ìŠ¹ì „ê²°ì´ë©´ ë” ì¢‹ê³ , ì •í™•í•˜ê²Œ ìš”ì•½í•´ì¤˜.

- ê° í•­ëª©ì€ 30ì ì´ë‚´, ìŒìŠ´ì²´ë¡œ
- ì¶œë ¥ì€ '-' 6ì¤„ ë¡œ ê¹”ë”í•˜ê²Œ

ì œëª©:
\"\"\"{title}\"\"\"

ë³¸ë¬¸:
\"\"\"{body}\"\"\"
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        max_completion_tokens=300
    )

    return response.choices[0].message.content.strip()


def url_summary(chat) -> str | None:
    """
    í…ìŠ¤íŠ¸ì—ì„œ URLì„ ì¶”ì¶œí•˜ê³  ê¸°ì‚¬ ìš”ì•½ ìˆ˜í–‰
    chat: ChatContext ê°ì²´
    """
    msg = chat.message.msg
    #msg = chat
    url_pattern = re.compile(r'https?://[^\s]+')
    url_match = url_pattern.search(msg)

    if url_match:
        url = url_match.group(0)
        print("âœ… ë©”ì‹œì§€ì—ì„œ URL ë°œê²¬:", url)
        try:
            article = fetch_article_content(url)
            summary = summarize_text(article)

            print("\nğŸ”¹ ì œëª©:", article.get("title", ""))
            print("ğŸ”¹ ìš”ì•½ ê²°ê³¼:")
            print(summary)
            return summary
        except Exception as e:
            print("âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
            return None
    else:
        print("âŒ ë©”ì‹œì§€ì— URLì´ ì—†ìŠµë‹ˆë‹¤:", msg)
        #return None
