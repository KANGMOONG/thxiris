import re
import time
import tempfile
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from urllib.parse import urlparse, parse_qs, unquote
from openai import OpenAI

# OpenAI í´ë¼ì´ì–¸íŠ¸ (í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”)
client = OpenAI()

def resolve_redirect_url(url: str, timeout=3) -> str:
    """
    ë‹¨ì¶• URL(naver.me ë“±)ì„ ì‹¤ì œ URLë¡œ ë³€í™˜
    (link.naver.com/bridge ì²˜ë¦¬ í¬í•¨)
    """
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        # HEAD ìš”ì²­ìœ¼ë¡œ ìµœì¢… URL í™•ì¸
        resp = requests.head(url, headers=headers, timeout=timeout, allow_redirects=True)
        final_url = resp.url

        # HEAD ì‹¤íŒ¨í•˜ë©´ GETìœ¼ë¡œ ì¬ì‹œë„
        if resp.status_code >= 400 or final_url == url:
            resp = requests.get(url, headers=headers, timeout=timeout, allow_redirects=True)
            final_url = resp.url

        # ğŸ”¹ Naver bridge URL ì²˜ë¦¬
        if "link.naver.com/bridge" in final_url:
            qs = parse_qs(urlparse(final_url).query)
            if "url" in qs:
                decoded = unquote(qs["url"][0])
                print("ğŸ”¹ Bridge URL â†’ ì‹¤ì œ URL:", decoded)
                return decoded

        return final_url
    except Exception as e:
        print("âš ï¸ ë¦¬ë‹¤ì´ë ‰íŠ¸ URL í•´ì„ ì‹¤íŒ¨:", e)
        return url

def try_requests_first(url: str, timeout=3) -> dict | None:
    """
    requests + BeautifulSoupìœ¼ë¡œ ê°„ë‹¨í•œ ê¸°ì‚¬ êµ¬ì¡° ë¹ ë¥´ê²Œ ì¶”ì¶œ
    """
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers, timeout=timeout)
        if not resp.ok or "text/html" not in resp.headers.get("Content-Type", ""):
            return None

        soup = BeautifulSoup(resp.text, "html.parser")
        title = soup.title.text.strip() if soup.title else ""
        body = soup.get_text(separator="\n")
        return {"title": title, "body": body[:4000]}
    except Exception as e:
        print("âš ï¸ requestsë¡œ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨:", e)
        return None

def fetch_with_selenium(url: str, wait_time=3) -> dict:
    """
    Seleniumìœ¼ë¡œ ê¸°ì‚¬ ë³¸ë¬¸ ë° ì œëª© ì¶”ì¶œ (ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬í•¨)
    """
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--blink-settings=imagesEnabled=false")
    options.add_argument("--disable-extensions")
    options.add_argument("--disable-default-apps")
    options.add_argument("--disable-popup-blocking")
    options.add_argument("--disable-notifications")
    options.add_argument("--mute-audio")

    temp_dir = tempfile.mkdtemp()
    options.add_argument(f"--user-data-dir={temp_dir}")

    driver = webdriver.Chrome(options=options)

    # ë¦¬ì†ŒìŠ¤ ì°¨ë‹¨
    driver.execute_cdp_cmd('Network.enable', {})
    driver.execute_cdp_cmd('Network.setBlockedURLs', {
        "urls": ["*.png", "*.jpg", "*.jpeg", "*.gif", "*.css", "*.woff", "*.ttf", "*.svg"]
    })

    title = ""
    body_text = ""

    try:
        driver.get(url)

        WebDriverWait(driver, wait_time).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )

        title = driver.title.strip()

        if "blog.naver.com" in url:
            try:
                WebDriverWait(driver, 5).until(
                    EC.presence_of_element_located((By.ID, "mainFrame"))
                )
                iframe = driver.find_element(By.ID, "mainFrame")
                driver.switch_to.frame(iframe)
                time.sleep(0.5)

                try:
                    article = driver.find_element(By.CLASS_NAME, "se-main-container")
                except:
                    article = driver.find_element(By.ID, "postViewArea")
                body_text = article.text.strip()
            except Exception as e:
                print("âš ï¸ ë„¤ì´ë²„ ë¸”ë¡œê·¸ iframe ì¶”ì¶œ ì‹¤íŒ¨:", e)
        else:
            body = driver.find_element(By.TAG_NAME, "body")
            body_text = body.text.strip()

    except Exception as e:
        print("âŒ Selenium ë³¸ë¬¸ ì¶”ì¶œ ì˜¤ë¥˜:", e)
    finally:
        driver.quit()

    return {"title": title, "body": body_text[:4000]}

def fetch_article_content(url: str) -> dict:
    """
    requestsë¡œ ë¨¼ì € ì‹œë„ í›„ ì‹¤íŒ¨ ì‹œ selenium fallback
    (ë„¤ì´ë²„ ë¸”ë¡œê·¸ëŠ” ëª¨ë°”ì¼ URLë¡œ ìë™ ë³€í™˜)
    """
    # ğŸ”¹ ë„¤ì´ë²„ ë¸”ë¡œê·¸ URLì„ ëª¨ë°”ì¼ URLë¡œ ë³€í™˜
    if "blog.naver.com" in url and not url.startswith("https://m."):
        url = url.replace("https://blog.naver.com", "https://m.blog.naver.com")

    article = try_requests_first(url)
    if article and article["body"].strip():
        return article
    return fetch_with_selenium(url)

def summarize_text(article: dict) -> str:
    """
    GPTë¡œ ê¸°ì‚¬ ë‚´ìš©ì„ í•µì‹¬ ìœ„ì£¼ë¡œ ìš”ì•½ (ì œëª© í¬í•¨)
    """
    title = article.get("title", "")
    body = article.get("body", "")

    if not body:
        return "- ë³¸ë¬¸ ì—†ìŒ\n- \n- \n- "

    prompt = f"""
ì œëª©ê³¼ ë³¸ë¬¸ì„ ë³´ê³ 
ê¸°ì‚¬ ë‚´ìš©ì„ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜.
ëˆ„ê°€ ë­˜ ì–´ë–»ê²Œ í–ˆëŠ”ì§€, ì¥ì†Œì™€ ì£¼ì²´, ëŒ€ìƒ êµ¬ì²´ì ìœ¼ë¡œ ë§í•´ì¤˜ì•¼
ë‚´ìš©ì˜ í˜¼ë™ì´ ì—†ìŒ.
ê¸°ìŠ¹ì „ê²°ì´ë©´ ë” ì¢‹ê³ , ì •í™•í•˜ê²Œ ìš”ì•½í•´ì¤˜.

- ê° í•­ëª©ì€ 30ì ì´ë‚´, ìŒìŠ´ì²´ë¡œ
- ì¶œë ¥ì€ 'âœ… ìš”ì•½'ì„ ì œì¼ ì²«ì¤„ë¡œ ì‹œì‘í•˜ê³ , ê·¸ ì•„ë˜ë¡œ '-' 6ì¤„ë¡œ ê¹”ë”í•˜ê²Œ ìš”ì•½

ì œëª©:
\"\"\"{title}\"\"\"

ë³¸ë¬¸:
\"\"\"{body}\"\"\"
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        max_completion_tokens=300
    )

    return response.choices[0].message.content.strip()

def url_summary(chat) -> str | None:
    """
    í…ìŠ¤íŠ¸ì—ì„œ URLì„ ì¶”ì¶œí•˜ê³  ê¸°ì‚¬ ìš”ì•½ ìˆ˜í–‰
    chat: ChatContext ê°ì²´
    """
    #msg = chat.message.msg
    msg=chat
    url_pattern = re.compile(r'https?://[^\s]+')
    url_match = url_pattern.search(msg)

    if url_match:
        url = url_match.group(0)
        print("âœ… ë©”ì‹œì§€ì—ì„œ URL ë°œê²¬:", url)

        # ğŸ”¹ ë‹¨ì¶• URL(ë¦¬ë‹¤ì´ë ‰íŠ¸) í’€ê¸° + ë¸Œë¦¬ì§€ URL ì²˜ë¦¬
        resolved_url = resolve_redirect_url(url)
        print("ğŸ”¹ ì‹¤ì œ URL:", resolved_url)

        try:
            article = fetch_article_content(resolved_url)
            summary = summarize_text(article)

            print("\nğŸ”¹ ì œëª©:", article.get("title", ""))
            print("ğŸ”¹ ìš”ì•½ ê²°ê³¼:")
            print(summary)
            return summary
        except Exception as e:
            print("âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
            return None
    else:
        print("âŒ ë©”ì‹œì§€ì— URLì´ ì—†ìŠµë‹ˆë‹¤:", msg)
        return None
